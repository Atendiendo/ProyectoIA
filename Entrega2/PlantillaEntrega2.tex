\documentclass[letter, 10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{url}
\usepackage[top=3cm,bottom=3cm,left=3.5cm,right=3.5cm,footskip=1.5cm,headheight=1.5cm,headsep=.5cm,textheight=3cm]{geometry}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows,automata,shapes.misc}
\usepackage{float}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{booktabs}


\begin{document}
\title{Inteligencia Artificial \\ \begin{Large}Informe Final: Enhanced Profitable Tour Problem\end{Large}}
\author{Miguel Huerta Flores}
\date{\today}
\maketitle


%--------------------No borrar esta secci\'on--------------------------------%
\section*{Evaluación}

\begin{tabular}{ll}
C\'odigo Fuente (20\%): &  \underline{\hspace{2cm}}\\
Resumen (2\%):  & \underline{\hspace{2cm}} \\
Introducci\'on (3\%):  & \underline{\hspace{2cm}} \\
Representaci\'on (10\%):  & \underline{\hspace{2cm}} \\
Descripci\'on del algoritmo (20\%):  & \underline{\hspace{2cm}} \\
Experimentos (10\%):  & \underline{\hspace{2cm}} \\
Resultados (10\%):  & \underline{\hspace{2cm}} \\
Conclusiones (20\%): &  \underline{\hspace{2cm}}\\
Bibliograf\'ia (5\%): & \underline{\hspace{2cm}}\\
 &  \\
\textbf{Nota Final (100)}:   & \underline{\hspace{2cm}}
\end{tabular}
%---------------------------------------------------------------------------%

\begin{abstract}
Este informe aborda el \textit{Enhanced Profitable Tour Problem} (EPTP), un problema de optimización combinatoria que busca
maximizar la rentabilidad de una ruta seleccionando un subconjunto de nodos bajo estrictas restricciones de ventanas de
tiempo. Dada su complejidad NP-Hard, se propone una solución aproximada basada en una metaheurística de \textit{Hill-Climbing}
con estrategia de reinicios múltiples. El documento detalla el modelo matemático, la implementación de operadores de vecindario
y un análisis experimental sobre instancias de hasta 140 nodos. Los resultados validan la eficacia del enfoque, demostrando su
capacidad para obtener soluciones factibles y competitivas en tiempos de ejecución reducidos, adecuados para aplicaciones logísticas reales.
\end{abstract}

\section{Introducción}
En los últimos años han surgido diversas empresas y aplicaciones que se centran en definir la ruta más óptima (Reparto urbano,
rutas turísticas, etc.) para maximizar la rentabilidad del negocio. Esta problemática de optimización es muy conocida y ha sido estudiada
extensivamente.
El problema mas clásico de enrutamiento es el Travelling Salesman Problem (TSP): el cual consiste en encontrar el camino más corto que
visita todos los nodos de un conjunto (con sus respectivos arcos), comenzando y terminando en el mismo punto.

El Enhanced Profitable Tour Problem (EPTP) es una generalización del
TSP: no es necesario visitar todos los nodos, cada nodo tiene una valoración propia según el usuario
y se busca maximizar el beneficio neto del recorrido teniendo en cuenta tanto las ganancias por visitar nodos como los arcos.

Este documento se divide en nueve partes:
\begin{itemize}
  \item \textbf{Definición del problema:} Se explica con detalle en qué consiste el EPTP, cuáles son sus variables, restricciones y
  objetivo(s). Además se presentan problemas relacionados y las variantes más conocidas.
  \item \textbf{Estado del arte:} Se detallan los estudios previos relevantes, comparando métodos exactos, heurísticos,
  metaheurísticos, hibridos (completos e incompletos) y técnicas emergentes aplicados a variantes cercanas.
  \item \textbf{Modelo matemático:} Se describe el modelo matemático propuesto/analizado, incluida la notación y las ecuaciones
  principales.
  \item \textbf{Representación:} Se fundamenta la elección de una codificación basada en permutaciones de enteros para modelar las
  rutas, justificando sus ventajas en términos de flexibilidad y eficiencia en el uso de memoria.
  \item \textbf{Descripción del algoritmo:} Se detalla el funcionamiento de la metaheurística implementada (\textit{Hill-Climbing}
  con reinicios), describiendo la lógica de los operadores de vecindario utilizados para la mejora local y la función de evaluación.
  \item \textbf{Experimentos:} Se define la metodología experimental diseñada para validar la propuesta, especificando las instancias
  de prueba, el entorno de hardware y los parámetros configurados para evaluar la escalabilidad y robustez del método.
  \item \textbf{Resultados:} Se presentan y discuten los datos cuantitativos obtenidos, utilizando tablas y gráficos para analizar el
  comportamiento del algoritmo respecto a la calidad de la solución, la factibilidad y los tiempos de ejecución.
  \item \textbf{Conclusiones:} Se exponen las conclusiones principales extraídas del análisis experimental y se sugieren líneas futuras
  de trabajo.
\end{itemize}

El propósito central de este informe es validar la eficacia de la estrategia de resolución propuesta, demostrando mediante evidencia
experimental su capacidad para gestionar la complejidad combinatoria del EPTP y generar soluciones factibles en tiempos competitivos.

\section{Definición del Problema}
Sea un grafo dirigido $G = (V, A)$, donde $V$ representa un conjunto de $n$ nodos y $A$ un conjunto de $m$ arcos. Tanto los
nodos como los arcos tienen asociadas una valorización y un tiempo de uso —tiempo de servicio en los nodos y tiempo de viaje en los
arcos— que dependen del usuario que realiza el tour.
El objetivo del EPTP consiste en seleccionar un subconjunto de nodos y arcos, de manera que se maximice la valorización neta del recorrido,
el tiempo total del tour no debe exceder el tiempo maximo del usuario $T$. Se introducen las variables binarias $x_{ij} \in$ \{0, 1\} que
indica si el arco ($i$, $j$) es parte del tour e $y_i \in$ \{0, 1\} que indica si el nodo $i$ es visitado. \cite{article}

En esta versión del problema, además, cada nodo cuenta con una ventana de tiempo $[e_i, l_i]$, que indica el intervalo en el cual
dicho nodo puede ser visitado.

Dado que el problema es una generalización del TSP, esto implica que es NP-Hard. Por lo tanto, 
en la práctica resulta inviable resolver instancias de tamaño medio o grande mediante métodos exactos
en tiempos computacionales razonables. Por esta razón, la literatura reciente se ha enfocado en el desarrollo 
de enfoques aproximados. Estos métodos buscan obtener soluciones
de alta calidad en tiempos reducidos, permitiendo abordar aplicaciones reales en ámbitos como la logística, 
la planificación de rutas de servicio y la gestión del transporte.

\textbf{Restricciones del problema}:
\begin{itemize}
    \item El tour comienza y termina en el nodo 1
    \item El tour consiste en un subconjunto de nodos
    \item Cada nodo del tour es visitado a lo más una vez
    \item Todos los usuarios comienzan en un tiempo inicial $t = 0$.
    \item La duración total del recorrido no debe exceder el tiempo total de cada usuario
    \item Cada nodo $i$ sólo puede visitarse dentro de su ventana de tiempo [$e_i$, $l_i$].
    \item Si se arriba antes de $e_i$, se espera; si se arriba después de $l_i$, el nodo no puede visitarse.
\end{itemize}

\textbf{Variantes mas conocidas}:
\begin{itemize}
  \item \textbf{Profitable Tour Problem Clásico}: Se combinan beneficios por visitar nodos y los costos por visitar nodos. Maximizando el
  beneficio neto. \cite{DASARI2021100897}
  \item \textbf{Orienteering Problem (OP)}: Se busca pasar por nodos (no necesariamente todos) con ``premios'' para maximizar ganancias, 
  dentro de un limite de tiempo. \cite{5668224}
  \item \textbf{Team Orienteering Problem (TOP)}: Se busca encontrar rutas para multiples vehiculos en un grafo, tal que,
  el profit de la suma de los nodos sea maximizado, sujeto al costo de que conlleva cada vehiculo. \cite{9155343}
  \item \textbf{Prize-Collecting TSP (PCTSP)}: Generalizacion del TSP. Al visitar un nodo, se recolecta un ``premio'' y por cada
  nodo no visitado, se penaliza. El objetivo es minimizar la suma de los costos de viaje y las penalizaciones, incluyendo en
  el tour, un numero suficiente de nodos para recolectar un ``premio'' minimo. \cite{1587725}
\end{itemize}

\section{Estado del Arte}

\subsection{Origen histórico del problema}
El problema de enrutamiento tiene su base en el conocido Traveling Salesman Problem (TSP).

Unos de los primeros estudios sobre el TSP fue hecho en 1949 por Julia Robinson ``On the Hamiltonian Game (A Traveling Salesman Problem)''
\cite{robinson1949hamiltonian} en el cual se presenta el objetivo del TSP como encontrar la ordenación cíclica de $n$
puntos de manera que la suma de las distancias entre puntos consecutivos sea mínima, se indica que para un numero grande de puntos
$n=50$, existen mas de $10^{62}$ caminos posibles, lo que hace imposible probarlos todos. Se propone un problema relacionado, en el cual
se busca un sistema de circuitos ordenados que minimicen la longitud total. Se describe un método utilizando matrices y se da un ejemplo
hecho ``a mano''. Cabe destacar que no se hace ningun analisis de tiempos o complejidades espaciales, solo se propone un método de resolución.

La formulación clásica del TSP es rígida, ya que impone la visita obligatoria a todos los nodos de una instancia. Si
bien esto es válido para muchos contextos teóricos, en la práctica logística esta premisa puede llevar a soluciones ineficientes y
poco rentables. Surgen, por ejemplo, situaciones en las que el costo de viajar hasta un cliente remoto supera el beneficio de atenderlo,
o donde sus restrictivas ventanas de tiempo hacen inviable su inclusión en una ruta cohesiva.

Esta limitación de los modelos clásicos motivó el desarrollo de variantes más flexibles y realistas. Una de las más relevantes es
el Profitable Tour Problem (PTP), que introduce un cambio de paradigma fundamental: no es obligatorio visitar todos los clientes.
En su lugar, el PTP busca maximizar la utilidad neta de la ruta, definida como la diferencia entre la suma de los beneficios (o premios)
obtenidos al visitar clientes y el costo total del recorrido. \cite{article}

Las primeras definiciones del PTP provienen del survey hecho en 2005 ``Traveling Salesman Problems With Profits'' \cite{article2}, donde se clasifican
los problemas de ruteo con ganancias. En este estudio, el Profitable Tour Problem (PTP) se define como el que busca determinar un
tour que maximice el beneficio neto, es decir, la diferencia entre el "profit" total recolectado de los vértices visitados y
el costo total de viaje. Este paper ha sido muy importante para el estudio de este problema, quedando reflejado por las mas de 600 citas
que tiene.

El Enhanced Profitable Tour Problem (EPTP) surge entonces como una evolución natural del PTP, incorporando restricciones operativas
críticas del mundo real (como ventanas de tiempo y tiempos de servicio) que condicionan la viabilidad y
rentabilidad del tour. Así, el EPTP no solo decide de forma óptima a qué clientes visitar, sino también en qué orden hacerlo,
respetando las restricciones que modelan el contexto operativo.

\subsection{Enfoques y técnicas utilizadas}

\subsubsection{Métodos exactos}
Este enfoque es presentado por \cite{LERAROMERO2021879}, quienes abordan el Problema de
time-dependent profitable tour problem with resource constraints (TDPTPRC). En este trabajo, los autores
desarrollan un algoritmo de Branch and Cut específicamente diseñado para este problema, que generaliza el Profitable Tour
Problem (PTP) al incorporar tiempos de viaje variables para modelar la congestión vial. Proponen una formulación de
programación lineal entera mixta (MILP) que, explotando la estructura de la función de tiempo de viaje,
reducen significativamente el número de variables y restricciones.

\subsubsection{Heurísticas}
En este contexto, \cite{1587725} propone dos algoritmos híbridos para resolver el Prize collecting travelling salesman problem
(PCTSP): el Evolutionary Clustering Search (ECS) y una adaptacion de este llamado *CS. Estos métodos se basan en una estrategia de
clustering de búsqueda para detectar áreas prometedoras del espacio de soluciones y luego aplicar métodos de búsqueda local para
refinarlas.

Por otro lado, \cite{9155343} aborda el Team orienteering problem (TOP), proponiendo
algoritmos de aproximación con ratios teóricos garantizados. Los autores desarrollan un algoritmo greedy con un
ratio de aproximación de $(1-(1/e)^{1/(2 + \epsilon)})$ para el caso general, y un algoritmo mejorado para el
caso especial donde todos los vehículos son del mismo tipo. Las evaluaciones experimentales muestran que sus algoritmos
superan en un 12.5\% a 17.5\% a los enfoques existentes en términos de profit obtenido.

Y por último, \cite{DASARI2021100897} se centra en el Profitable Tour Problem (PTP), proponiendo tres métodos: multi-start
hyper-heuristic (MSHH), multi-start iterated local search (MS-ILS) and multi-start general variable neighborhood search (MS-GVNS).
La hyper-heurística MSHH utiliza ocho heurísticas de bajo nivel (como adición, eliminación, intercambio y 2-opt) y dos mecanismos
de selección: aleatorio (MSHH\_RAND) y greedy (MSHH\_GREEDY). Los experimentos en 77 instancias basadas en TSPLIB muestran que
MSHH\_RAND y MSHH\_GREEDY superan consistentemente a MS-ILS y MS-GVNS en la mayoría de los casos, tanto en calidad de solución best
como average, con MSHH\_RAND siendo el método más efectivo en general, especialmente bajo criterios de tiempo corto.

\subsubsection{Metaheurísticas}
Por el lado de las Metaheurísticas, \cite{5668224} propone un algoritmo de Modified Variable Neighborhood Search (MVNS) para resolver el
Orienteering Problem (OP). A diferencia de los métodos clásicos de Variable Neighborhood Search (VNS), el MVNS divide el espacio de
búsqueda en sub-regiones según los niveles de restricción. Durante la búsqueda, selecciona una solución base de una lista de candidatos
que contiene una solución por cada nivel de restricción, y las soluciones vecinas encontradas se comparan y actualizan globalmente
en dicha lista. El algoritmo incorpora dos tipos de procedimientos de vecindad: path improvement (intercambio, 2-opt e inserción,
tanto intra-ruta como inter-rutas) y score improvement (reemplazo e inserción de nodos no visitados). Además,
utiliza una fase de perturbación para diversificar la búsqueda. En pruebas con 67 instancias benchmark, MVNS obtuvo
65 de las mejores soluciones conocidas, demostrando ser robusto y eficiente en comparación con otros métodos como ACO-OP, VNS y NACO-OP.

Por otro lado, \cite{6552660} aborda el Rich Profitable Tour Problem (RPTP). Los autores proponen un
algoritmo híbrido que combina Variable Neighborhood Search con Adaptive Large Neighborhood Search (VNS/ALNS). Este método
utiliza una fase de perturbación basada en el paradigma Ruin and Recreate, que destruye parcialmente la solución y luego la
repara mediante heurísticas adaptativas de inserción y eliminación. La fase de mejora emplea una búsqueda local que reinserta
clientes no visitados. Cuando se evalúa en instancias del Orienteering Problem with Time Windows (OPTW), el algoritmo VNS/ALNS
obtiene soluciones óptimas o casi óptimas en 57 de 58 instancias, superando en rendimiento a métodos como ILS, GRASP/ELS y GVNS.

\subsubsection{Métodos híbridos}
En el contexto de sistemas de información turística, \cite{article} propone un marco híbrido para resolver el Enhanced Profitable
Tour Problem (EPTP). Este enfoque combina técnicas de reducción de grafos, construcción inicial de rutas y mejora iterativa
mediante un algoritmo único de Extensión/Colapso. Primero, el grafo original de la red vial se reduce conservando solo los nodos de
interés y calculando caminos óptimos entre ellos mediante un algoritmo de Dijkstra modificado que considera preferencias del usuario.
Luego, se genera una solución inicial factible insertando nodos de manera iterativa según un criterio de ganancia por unidad de tiempo.
Finalmente, la fase de mejora alterna entre una Fase de Extensión, que añade nodos prometedores al tour, y una Fase de Colapso, que
elimina nodos para mantener la factibilidad respecto al tiempo máximo. Este enfoque híbrido logra soluciones de alta calidad
(más del 90\% del óptimo en comparación con branch and bound) en tiempos computacionales razonables (3.7 segundos para un tour de 8
horas), siendo adecuado para aplicaciones en tiempo real.

En un enfoque más reciente, \cite{HE2025107077} introduce el Capacitated Profitable Tour Problem with Cross-Docking (CPTPC),
un problema de enrutamiento de dos niveles donde empresas logísticas seleccionan solicitudes de transporte rentables desde plataformas
industriales y utilizan un cross-dock para consolidar envíos. Los autores desarrollan un Hybrid Genetic Algorithm (HGA) que incorpora un
operador de cruce de dos niveles EAX² para combinar rutas de recogida y entrega de soluciones parentales, manteniendo bloques prometedores.
El algoritmo también incluye una búsqueda local con once operadores de vecindad (M1-M11) y una técnica de cálculo optimizada que utiliza
colas de prioridad para evaluar inserciones de nodos de entrega de manera eficiente. Las pruebas en instancias reales de 36 solicitudes
muestran que HGA mejora los beneficios entre un 59.74\% y un 124.31\% respecto a métodos manuales, demostrando su utilidad práctica
para la logística basada en plataformas digitales.

\subsubsection{Técnicas emergentes}
Finalmente, \cite{9989933} aborda el Online Stochastic Profitable Tour Problem
(OS-PTP), una variante del TSP con beneficios donde las ganancias de los clientes se modelan mediante variables aleatorias dependientes
del tiempo cuyas realizaciones se revelan de forma incremental. Los autores proponen un algoritmo de Deep Reinforcement Learning (DRL)
basado en AlphaZero, que combina una red neuronal convolucional con una búsqueda en árbol de Monte Carlo (MCTS). La red neuronal
procesa matrices de entrada que representan la posición actual del agente, los beneficios esperados y el tiempo restante, generando
dos salidas: un valor de estado (value-head) que estima la ganancia futura esperada y una distribución de probabilidad (policy-head)
sobre los próximos clientes a visitar. Durante la fase en línea, el MCTS guiado por la red, explora iterativamente los movimientos más
prometedores mediante una función UCT que balancea exploración y explotación. El entrenamiento se realiza mediante auto-juego en
1,000 escenarios de cada instancia, actualizando la red con los datos generados por el MCTS. En pruebas con instancias de 10 a 50
clientes, el algoritmo mejora progresivamente su rendimiento, alcanzando hasta un 97\% del óptimo de referencia tras 4 días de
entrenamiento. Este enfoque representa un avance significativo en la aplicación de DRL a problemas de enrutamiento estocásticos,
eliminando la necesidad de diseñar heurísticas manuales y adaptándose dinámicamente a la incertidumbre en la demanda.

\subsection{Resumen Estado del Arte}
Si bien la revisión abarca una gama de problemas relacionados (PTP, OP, TOP), el análisis comparativo se orienta a identificar las
técnicas más adecuadas para abordar el Enhanced Profitable Tour Problem (EPTP), el cual se caracteriza por la selección óptima de
clientes, la maximización de la utilidad y, críticamente, la incorporación de restricciones operativas realistas como ventanas de tiempo.

Desde esta perspectiva, los métodos exactos \cite{LERAROMERO2021879} quedan descartados para instancias realistas de EPTP debido a su
alta complejidad computacional. La introducción de ventanas de tiempo y otros recursos hace que el espacio de búsqueda sea demasiado
grande para que estos métodos sean viables en aplicaciones prácticas, aunque siguen siendo valiosos para obtener soluciones de referencia
en instancias pequeñas.

Entre las metodologías aproximadas, las metaheurísticas y heurísticas avanzadas demuestran ser las más robustas. En particular,
los enfoques híbridos que combinan diferentes estrategias de búsqueda son los que mejor se adaptan a la naturaleza combinatoria y
fuertemente restringida del EPTP. El algoritmo MVNS de \cite{5668224} y el VNS/ALNS de \cite{6552660}, ambos probados en problemas
con ventanas de tiempo (OPTW), son ejemplos destacados. Su éxito radica en la capacidad de equilibrar una búsqueda local intensiva
(para explotar soluciones prometedoras) con mecanismos de diversificación efectivos, para escapar de óptimos locales.

Por otro lado, las técnicas emergentes como el DRL \cite{9989933} si bien son extremadamente prometedoras para entornos dinámicos y
estocásticos (una posible extensión futura del EPTP), actualmente presentan una barrera de entrada alta por su costo de entrenamiento
y complejidad de implementación. Para el EPTP en su formulación estática y determinística, las metaheurísticas híbridas consolidadas
ofrecen una mejor relación costo-beneficio.

\section{Modelo Matemático}
El siguiente modelo matematico fue creado usando \cite{article}, \cite{VANSTEENWEGEN20111} y el documento entregado por el ayudante asociado
al problema Marcel Silva.

Dado un grafo dirigido $G = (V, A)$ donde $V$ es un conjunto de $n$ nodos, y $A$ es un conjunto de $m$ arcos, considerando solo
1 usuario por instancia:

\subsection{Parámetros y constantes}
\begin{itemize}
  \item $V = \{1, 2, . . . , n\}$: conjunto de nodos.
  \item $A \subseteq V$ x $V$: conjunto de arcos dirigidos.
  \item $t_i$: tiempo de servicio en el nodo $i$. $i \in V$.
  \item $d_{ij}$ : tiempo de viaje asociado al arco ($i$, $j$) $\in A$.
  \item $T$: tiempo total del usuario.
  \item $c_{ij}$: valorización del arco ($i$, $j$) que le da el usuario. $i$, $j \in V$
  \item $s_i$: valorización del nodo $i$ que le da el usuario. $i \in V$
  \item $[e_i, l_i]$: ventana de tiempo en la que el nodo $i$ está disponible. $i \in V$
  \item $M$: una constante numerica muy grande.
\end{itemize}

\subsection{Variables}
\begin{itemize}
  \item $x_{ij} \in$ \{0, 1\}: variable que indica si el arco ($i$, $j$) es parte del tour.
  \item $y_i \in$ \{0, 1\}: variable que indica si el nodo $i$ es visitado.
  \item $w_i \geq 0$: variable continua que representa el tiempo de inicio del servicio en $i$.
\end{itemize}

\subsection{Función Objetivo}

\begin{equation}
maximize \sum_{i \in V} s_i y_i + \sum_{i \in V}\sum_{j \in V \setminus \{i\}} c_{ij} x_{ij}
\end{equation}

(1) Representa la función objetivo, expresa la maximización de las valorizaciones de los arcos y los nodos por parte
del usuario.

\subsection{Restricciones}
\begin{equation}
\sum_{j \in V \setminus \{i\}} x_{ij} - y_i = 0, \quad \forall i \in V
\end{equation}
\begin{equation}
\sum_{i \in V \setminus \{j\}} x_{ij} - y_j = 0, \quad \forall j \in V
\end{equation}
(2) y (3) se aseguran que los nodos solo tengan 1 arco de entrada y 1 arco de salida.

\begin{equation}
y_1 = 1
\end{equation}
\begin{equation}
w_1 = 0
\end{equation}

En (4) por simplicidad se determina el nodo inicial fijo y en (5) se determina que el servicio en el nodo 1 comienza en el tiempo 0.

\begin{equation}
e_i y_i \leq w_i \leq l_i y_i, \quad \forall i \in V \setminus \{1\}
\end{equation}
En (6), se fuerza a que el tiempo de inicio del servicio este dentro de la ventana de tiempo [$e_i$, $l_i$] solo si el nodo es visitado.
\begin{itemize}
  \item si $y_i = 1$ (nodo $i$ es visitado) la restriccion se vuelve $e_i \leq w_i \leq l_i$ obligando a que $w_i$ se encuentre en el rango.
  \item si $y_i = 0$ (nodo $i$ no es visitado) la restriccion se vuelve $0 \leq w_i \leq 0$ lo que fuerza $w_i = 0$.
\end{itemize}

\begin{equation}
w_j \geq w_i + t_i + d_{ij} - M(1-x_{ij}), \quad \forall(i,j) \in A, j \neq 1
\end{equation}
En (7) nos aseguramos que $w_j$ se vaya actualizando correctamente:
\begin{itemize}
  \item si $x_{ij} = 1$ (se viaja de $i$ a $j$), la restriccion se vuelve $w_j \geq w_i + t_i + d_{ij}$, lo que nos asegura que el
  servicio en $j$ ($w_j$) comience despues de llegar a $j$.
  \item si $x_{ij} = 0$, la restriccion se vuelve $w_j \geq w_i + t_i + d_{ij} - M$ lo cual es un numero negativo muy grande y la restriccion
  no se activa.
\end{itemize}

\begin{equation}
w_i + t_i + d_{i1} \leq T + M(1-x_{i1}), \quad \forall i \in V \setminus \{1\}
\end{equation}
En (8) se asegura de que no se sobrepase el tiempo maximo del usuario.
\begin{itemize}
  \item si $x_{ij} = 1$ (el arco ($i$, 1) se usa, entonces $i$ el es el ultimo nodo), la restriccion se activa: $w_i + t_i + d_{i1} \leq T$
  Esto se asegura que la vuelta al inicio (nodo 1) sea menor a $T$.
  \item si $x_{ij} = 0$ (no se esta en el ultimo nodo), la restriccion queda $w_i + t_i + d_{i1} \leq T + M$ y la restriccion no se activa.
\end{itemize}

\begin{equation}
x_{ij} \in \{0, 1\}, \quad \forall (i,j) \in A
\end{equation}
\begin{equation}
y_i \in \{0, 1\}, \quad \forall i \in V
\end{equation}
\begin{equation}
w_i \ge 0, \quad \forall i \in V
\end{equation}
Finalmente en (9), (10) y (11) se definen la naturaleza de las variables.

\subsection{Espacio de búsqueda}
La variable $y_i$ tiene espacio $2^n$, mientras que la variable $x_{ij}$ tiene espacio $2^{n^2}$,
juntando ambas, el espacio total de este modelo es $2^{n + n^2}$

Es importante notar que las variables continuas $w_i$ no incrementan este espacio de búsqueda 
combinatorio; su rol es definir el dominio para la verificación de la factibilidad temporal 
(ventanas de tiempo) dentro de cada combinación binaria generada por $x_{ij}$ e $y_i$.

\section{Representación}
Se ha seleccionado una representación de permutación de enteros para codificar las soluciones.
En esta estructura, una solución se define como una secuencia ordenada de nodos, donde cada
elemento corresponde a un identificador único de un nodo visitado y la posición en la lista indica el orden de visita.

Como se definió en la sección anterior, el nodo inicial es fijo (nodo 1). Por consiguiente, la estructura asume implícitamente
que el recorrido comienza en dicho nodo y que existe una arista de retorno desde el último elemento de la lista hacia el primero,
cerrando así el ciclo. Aquellos nodos que no se encuentran en la lista se consideran no visitados en la solución actual.

Cabe destacar que esta codificación no impone el cumplimiento estricto de las restricciones específicas del problema
(como capacidad o ventanas de tiempo). Por lo tanto, el espacio de búsqueda abarca tanto soluciones factibles como infactibles.
Estas últimas son admitidas temporalmente durante el proceso de búsqueda para permitir una exploración más fluida,
siendo penalizadas en la función objetivo según el tiempo sobrepasado.

\subsection{Justificación de la Representación}
\begin{itemize}
  \item \textbf{Eficiencia y Reducción del Espacio de Búsqueda:} A diferencia de una matriz binaria de adyacencia, esta lista compacta
  almacena solo la información relevante (nodos visitados y su secuencia), eliminando la redundancia de representar aristas
  inexistentes o nodos no visitados.
  \item \textbf{Relación Uno a Uno:} Existe una relación clara entre la representación y la solución física; cualquier permutación válida
  de un subconjunto de nodos se traduce en un único tour.
  \item \textbf{Flexibilidad de Representación:} La estructura es lo suficientemente flexible para representar la solución óptima global,
  permitiendo soluciones de tamaño variable.
  \item \textbf{Manipulación:} Facilita la implementación de operadores de búsqueda local (como swap, addition o 2-opt) al requerir simplemente
  el cambio de índices en la secuencia.
\end{itemize}

\subsection{Ejemplo}
A continuación, se presenta un esquema visual de una solución factible y su correspondiente codificación.

\shorthandoff{>}
\begin{figure}[H]
  \centering
  \begin{tikzpicture}[->, auto, node distance=1.8cm, thick]

  \tikzstyle{every state}=[draw, text=black]

  % nodos
  \node[state] (1) at (90:2) {1};   % arriba
  \node[state] (2) at (18:2) {2};
  \node[state] (3) at (-54:2) {3};
  \node[state] (4) at (-126:2) {4};
  \node[state] (5) at (162:2) {5};

  % aristas
  \path (1) edge (2)
        (2) edge (3)
        (3) edge (4)
        (4) edge (1);

  \end{tikzpicture}
  \caption{Representación gráfica de un tour que visita los nodos 1, 2, 3 y 4.}
  \label{fig:ejemplo_tour}
\end{figure}
\shorthandon{>}

Tal como se aprecia en la Figura \ref{fig:ejemplo_tour}, el tour recorre la secuencia de nodos visitados excluyendo al nodo 5.
La representación en forma de lista para esta solución específica corresponde a: $[1,2,3,4]$ Esta lista indica que el recorrido
inicia en 1, avanza secuencialmente hacia 2, 3 y 4, y finalmente retorna al nodo 1

\section{Descripción del algoritmo}

\subsection{Visión general del enfoque}
La solución implementada corresponde a un algoritmo de Hill-Climbing con Restart Best Improvement.
El enfoque combina dos ideas principales:
(i) intensificación, mejorando iterativamente una solución inicial mediante operadores locales, y
(ii) diversificación, introducida a través de reinicios que permiten escapar de óptimos locales.
La estructura general y el flujo de control del procedimiento propuesto se detallan en el Algoritmo \ref{alg:hill_climbing_restarts}.

\subsection{Generación de solución inicial}
La solución inicial se genera construyendo una permutación aleatoria que contiene aproximadamente la mitad de los nodos disponibles.
Este mismo procedimiento se utiliza cada vez que ocurre un reinicio. La implementacion se detalla en
Algoritmo \ref{alg:crear_solucion_aleatoria}.

La elección de generar únicamente la mitad del número total de nodos es por razones de factibilidad.
En etapas iniciales se intentó construir soluciones que incluyeran todos los nodos, pero estas solían resultar infactibles y
requerían un número significativamente mayor de iteraciones para converger hacia una solución válida.

\subsection{Función de evaluación}
La función de evaluación analiza secuencialmente la permutación construida (Algoritmo \ref{alg:funcion_evaluacion}) y:
\begin{itemize}
  \item acumula los beneficios de nodos y arcos,
  \item suma los tiempos de viaje y servicio,
  \item respeta las ventanas de tiempo (esperando si se llega antes),
  \item penaliza las violaciones de ventanas y del tiempo máximo del usuario, marcando la solución como infactible cuando corresponde.
\end{itemize}

\subsection{Operadores / movimientos}
Los operadores de vecindario seleccionados se basan en la versión estocástica de la heurística
Multi-start hyper-heuristic approaches for PTP \(MSHH\_RAND\), propuesta por \cite{DASARI2021100897}.
Esta elección se justifica por el desempeño superior que dicha configuración demostró para el problema PTP en la literatura
de referencia. Los operadores considerados son:
\begin{itemize}
  \item \textbf{Addition}: inserta un nodo del conjunto de no visitados en el tour, con el objetivo de intensificar la búsqueda.
  Algoritmo \ref{alg:addition}.
  
  \item \textbf{Delete}: elimina un nodo del tour, generalmente para corregir infactibilidades asociadas al tiempo máximo.
  Algoritmo \ref{alg:eliminacion}
  \item \textbf{Swap}: intercambia dos nodos dentro del tour, promoviendo intensificación. Algoritmo \ref{alg:swap}
  \item \textbf{Exchange}: intercambia un nodo dentro del tour con uno fuera del tour. Algoritmo \ref{alg:exchange}
  \item \textbf{2-opt}: revierte un segmento del tour, reduciendo potencialmente el costo del recorrido. Algoritmo \ref{alg:opt_2}
\end{itemize}

Ninguno de estos movimientos emplea parámetros adicionales específicos; la búsqueda se guía únicamente por la solución
actual y por el vecindario generado por el operador seleccionado.

\section{Experimentos}
\subsection{Objetivos experimentación}
El objetivo de la experimentación es analizar cómo los principales parámetros del algoritmo afectan la calidad, factibilidad y
tiempo de ejecución de las soluciones generadas. Para ello, se estudiaron dos factores independientes:
(i) la cantidad de nodos del problema, y
(ii) el número de reinicios del algoritmo Hill-Climbing.

\subsection{Instancias elegidas}
Para la experimentación se utilizaron las instancias oficiales proporcionadas por el ayudante en el proyecto, las cuales incluyen
tanto los archivos Tipo 1 (información de nodos, tiempos y ventanas) como los archivos Tipo 2 (perfiles de usuarios, beneficios y
tiempos máximos). Estas instancias permiten evaluar el desempeño del algoritmo en distintos escenarios, con diferentes distribuciones
de beneficios, ventanas de tiempo y restricciones operacionales.

El análisis respecto a la cantidad de nodos se realizó aplicando el algoritmo a todas las instancias disponibles con tamaños
comprendidos entre 10 y 140 nodos, evaluando cómo la escala del problema afecta la factibilidad, el tiempo de ejecución y la
calidad de las soluciones obtenidas. Cada instancia fue ejecutada 10 veces utilizando distintas semillas aleatorias, con el
objetivo de capturar la variabilidad inherente a la naturaleza estocástica del método.

Por otro lado, para estudiar el impacto de la cantidad de reinicios, se seleccionó una instancia representativa de tamaño
intermedio dentro del conjunto entregado (instancia de 100 nodos). Sobre esta instancia se evaluaron
configuraciones con 10, 50, 100, 500 y 1000 reinicios, manteniendo constante el resto de los parámetros.

\subsection{Hardware utilizado}
Los experimentos se ejecutaron en una máquina con las siguientes características:
\begin{itemize}
  \item \textbf{Procesador:} Intel(R) Core(TM) i5-9300H CPU @ 2.40GHz
  \item \textbf{Memoria RAM:}  16 GB DDR4-2666 (1333 MHz) X 2 (32 GB totales)
  \item \textbf{Sistema operativo:} Windows 11 Home 25H2
  \item \textbf{Entorno de ejecución:} WSL Ubuntu 22.04.1 LTS
  \item \textbf{Almacenamiento:}  Intel Optane 238GB SSD NVMe
\end{itemize}

\subsection{Parámetros y detalles importantes}
\begin{itemize}
  \item \textbf{Cantidad de Nodos:} Se estudió el efecto del tamaño del problema sobre: el tiempo de ejecución, la factibilidad de
  las soluciones generadas, y el valor de la función de evaluación. Para ello se analizaron las instancias con 10, 20, 30, ..., 140
  nodos, manteniendo constantes las demás características del problema.
  Cada instancia se ejecutó 10 veces con diferentes semillas para observar la variabilidad del método debido a su componente estocástico.
  El número de reinicios se mantuvo fijo en 10. Y se ocupo la instancia con la mayor cantidad de usuarios.
  \item \textbf{Cantidad de Restarts:} Para estudiar el efecto de la diversificación del algoritmo, se utilizó una única instancia
  con 100 nodos y se variaron los valores de reinicios a: 10, 50, 100, 500 y 1000. Cada instancia se ejecutó 10 veces con diferentes
  semillas, con la mayor cantidad de usuarios de la instancia (45). Este
  experimento permite evaluar cómo la cantidad de reinicios afecta: la capacidad de escapar de óptimos locales, la factibilidad del tour,
  el tiempo total de ejecución, y la calidad final de la solución.
\end{itemize}

\section{Resultados}

\subsection{Experimento 1}
El primer experimento tuvo como objetivo estudiar cómo varía el desempeño del algoritmo en función de la cantidad de nodos
presentes en la instancia. Para ello, se ejecutó el método sobre instancias que van desde 10 hasta 140 nodos. Cada instancia fue
evaluada 10 veces utilizando distintas semillas, y se mantuvo fija la cantidad de reinicios en 10.

Los resultados se resumen en el Cuadro \ref{tab:resultados_tarea1}, donde se presenta el número promedio de soluciones factibles e
infactibles encontradas a
lo largo de las ejecuciones. El análisis de estos datos permite identificar varios patrones relevantes.
\begin{table}[htbp]
    \centering
    \caption{Resultados del experimento 1}
    \label{tab:resultados_tarea1}
    \begin{tabular}{crrrc}
        \toprule
        \textbf{Nodos} & \textbf{Factibles} & \textbf{No Fact.} & \textbf{Tiempo prom. ($\mu$s)} & \textbf{Aptitud prom.} \\
        \midrule
        10  & 6,8  & 0,2 & 206,60   & 87,3  \\
        20  & 10,7 & 0,3 & 713,70   & 118,6 \\
        30  & 14,3 & 0,7 & 1637,85  & 136,4 \\
        50  & 26,2 & 0,8 & 5289,16  & 162,1 \\
        70  & 17,5 & 0,5 & 11451,89 & 182,5 \\
        80  & 41,2 & 0,8 & 14594,39 & 183,4 \\
        100 & 44,2 & 0,8 & 22942,80 & 186,6 \\
        110 & 51,8 & 0,2 & 28914,60 & 188,9 \\
        120 & 61,7 & 0,3 & 36042,87 & 192,5 \\
        140 & 71,4 & 0,6 & 53051,19 & 203,0 \\
        \bottomrule
    \end{tabular}
\end{table}

A partir de los resultados mostrados en el Cuadro 2, se observa que el algoritmo logra,
en general, una cantidad considerable de soluciones factibles en prácticamente todas las instancias evaluadas. Incluso en los
casos de mayor tamaño, el número de soluciones válidas aumenta de forma consistente, mientras que la cantidad de soluciones no
factibles se mantiene siempre muy baja (entre 0.2 y 0.8 en promedio).

\begin{table}[h!]
\label{tab:resultados_factibilidad}
\centering
\begin{tabular}{c c c}
\hline
\textbf{Cantidad de nodos} & \textbf{Factibles} & \textbf{No factibles} \\
\hline
10  & 6.8  & 0.2 \\
20  & 10.7 & 0.3 \\
30  & 14.3 & 0.7 \\
50  & 26.2 & 0.8 \\
70  & 17.5 & 0.5 \\
80  & 41.2 & 0.8 \\
100 & 44.2 & 0.8 \\
110 & 51.8 & 0.2 \\
120 & 61.7 & 0.3 \\
140 & 71.4 & 0.6 \\
\hline
\end{tabular}
\caption{Resultados de factibilidad por cantidad de nodos.}
\end{table}

La Figura \ref{fig:GraficoavgaptVSnodos} muestra la relación entre la cantidad de nodos de la instancia y la aptitud promedio obtenida por el algoritmo.
Se observa una tendencia claramente creciente: a medida que aumenta el número de nodos disponibles, el valor promedio de
aptitud también se incrementa de forma sostenida.

Este comportamiento es coherente con la naturaleza del EPTP, ya que un mayor número de nodos incrementa el potencial máximo
de recompensa disponible en el problema. Por tanto, el algoritmo dispone de más oportunidades para construir rutas que acumulen
un mayor puntaje. Además, la curva presenta un crecimiento
particularmente pronunciado entre 10 y 70 nodos, estabilizándose luego en un incremento más moderado, lo cual sugiere que el algoritmo
sigue aprovechando nodos adicionales, aunque con un beneficio marginal decreciente.

Por otra parte, es crucial analizar el costo computacional asociado a obtener estas soluciones. La Figura
\ref{fig:GraficoavgtimeVSnodos} expone la evolución del tiempo promedio de ejecución (medido en microsegundos)
conforme aumenta la cantidad de nodos.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.5\textwidth}
      \includegraphics[width=\textwidth]{Graficos/avgaptVSnodos.png}
      \caption{Aptitud promedio vs nodos.}
      \label{fig:GraficoavgaptVSnodos}
    \end{minipage}%
    \begin{minipage}[t]{0.5\textwidth}
      \includegraphics[width=\textwidth]{Graficos/avgtimeVSnodos.png}
      \caption{Aptitud promedio vs nodos.}
      \label{fig:GraficoavgtimeVSnodos}
    \end{minipage}%
\end{figure}

Al observar la gráfica, se evidencia que el tiempo de ejecución no crece de manera lineal, sino que sigue una tendencia que
aparenta ser polinomial (posiblemente cuadrática). En las instancias pequeñas (de 10 a 30 nodos), el tiempo es prácticamente
despreciable y la curva se mantiene plana. Sin embargo, a partir de los 50 nodos, la pendiente comienza a pronunciarse,
acelerándose notablemente en el intervalo de 100 a 140 nodos.

Este comportamiento es esperable y se justifica por el aumento
en la complejidad del espacio de búsqueda. Al incrementar el número de nodos, aumenta factorialmente la cantidad de posibles
permutaciones de rutas y cuadráticamente la matriz de distancias, lo que obliga al algoritmo a realizar un mayor número de
operaciones para evaluar la factibilidad y calcular la función objetivo en cada uno de los 10 reinicios configurados.

Sin embargo, es fundamental destacar la magnitud de los valores temporales. A pesar de la forma ascendente de la curva,
el tiempo máximo registrado para la instancia más compleja (140 nodos) es de aproximadamente 53000 $\mu$s, lo que equivale
a 0.053 segundos. Esto indica que, aunque el algoritmo requiere más tiempo para instancias grandes, sigue siendo extremadamente
eficiente en términos absolutos, resolviendo el problema en una fracción de segundo, lo cual es un indicador muy positivo
para su viabilidad en aplicaciones de tiempo real.

\subsection{Experimento 2}
El segundo experimento tuvo como objetivo estudiar cómo varía el desempeño del algoritmo en función de la cantidad de reinicios
(Restarts) configurados. Para ello, se utilizó una instancia de tamaño fijo (100 nodos) evaluada sobre 45 usuarios, variando
la cantidad de reinicios en el conjunto $\{10, 50, 100, 500, 1000\}$.

Los resultados se resumen en el Cuadro \ref{tab:resultados_tarea2}, donde se presenta el promedio de las métricas clave obtenidas
tras las ejecuciones. El análisis de estos datos permite comprender el impacto de la intensificación y diversificación en la búsqueda.

\begin{table}[htbp]
    \centering
    \caption{Resultados del experimento 2}
    \label{tab:resultados_tarea2}
    \begin{tabular}{crrrc}
        \toprule
        \textbf{Restarts} & \textbf{Factibles} & \textbf{No Fact.} & \textbf{Tiempo prom. ($\mu$s)} & \textbf{Aptitud prom.} \\
        \midrule
        10   & 44,2 & 0,8 & 2,19E+04 & 186,6 \\
        50   & 44,5 & 0,5 & 1,10E+05 & 208,3 \\
        100  & 44,4 & 0,6 & 2,20E+05 & 216,9 \\
        500  & 44,1 & 0,9 & 1,09E+06 & 231,3 \\
        1000 & 44,5 & 0,5 & 2,21E+06 & 235,8 \\
        \bottomrule
    \end{tabular}
\end{table}

A partir de los resultados mostrados en el Cuadro \ref{tab:resultados_restarts}, se destaca una notable estabilidad en la tasa
de soluciones factibles encontradas. Independientemente de si el algoritmo se reinicia 10 o 1000 veces, la proporción de soluciones que
respetan todas las restricciones se mantiene constante y alta, promediando alrededor de 44.5 usuarios con solución factible de un total de 45.

Esto sugiere que la capacidad del algoritmo para encontrar soluciones válidas no depende de la "fuerza bruta" de los reinicios, sino de
la robustez de los operadores de reparación (específicamente el operador Delete) y la función de evaluación diseñados.

\begin{table}[htbp]
    \centering
    \caption{Comparación de resultados según cantidad de Restarts}
    \label{tab:resultados_restarts}
    \begin{tabular}{ccc}
        \toprule
        \textbf{Restarts} & \textbf{Factibles} & \textbf{No Factibles} \\
        \midrule
        10   & 44,2 & 0,8 \\
        50   & 44,5 & 0,5 \\
        100  & 44,4 & 0,6 \\
        500  & 44,1 & 0,9 \\
        1000 & 44,5 & 0,5 \\
        \bottomrule
    \end{tabular}
\end{table}

La Figura \ref{fig:GraficoavgaptVSrestarts} ilustra la relación entre la cantidad de reinicios y la aptitud promedio obtenida.
Se observa un comportamiento de \textbf{rendimientos decrecientes}. Existe un incremento notable en la calidad de la solución al
pasar de 10 a 50 y 100 reinicios (la curva tiene una pendiente pronunciada inicialmente), lo que indica que los primeros reinicios
son críticos para escapar de óptimos locales pobres.

Sin embargo, a medida que la cantidad de reinicios aumenta hacia 500 y 1000, la curva se suaviza. Aunque la aptitud sigue
mejorando (alcanzando su máximo de 235,8 con 1000 reinicios), la ganancia marginal por cada reinicio adicional es menor. Esto
indica que el algoritmo comienza a saturar su capacidad de búsqueda en el espacio de soluciones disponible para esta instancia.

Por otra parte, es crucial analizar el costo computacional. La Figura \ref{fig:GraficoavgtimeVSrestarts} expone
la evolución del tiempo promedio de ejecución.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.5\textwidth}
      \includegraphics[width=\textwidth]{Graficos/avgaptVSrestarts.png}
      \caption{Aptitud promedio vs nodos.}
      \label{fig:GraficoavgaptVSrestarts}
    \end{minipage}%
    \begin{minipage}[t]{0.5\textwidth}
      \includegraphics[width=\textwidth]{Graficos/avgtimeVSrestarts.png}
      \caption{Aptitud promedio vs nodos.}
      \label{fig:GraficoavgtimeVSrestarts}
    \end{minipage}%
\end{figure}

Al observar la gráfica de tiempos, se confirma un crecimiento estrictamente \textbf{lineal}. La gráfica muestra una recta ascendente
donde el tiempo es directamente proporcional al número de reinicios. Esto es evidente al comparar los puntos finales: al duplicar
los reinicios de 500 a 1000, el tiempo también se duplica (pasando de $\approx 1.1 \times 10^6$ a $\approx 2.2 \times 10^6 \mu s$).
Los valores bajos (10 a 100) parecen planos visualmente solo debido a la magnitud de la escala vertical, pero siguen la misma proporción
lineal.

Este comportamiento lineal, contrastado con la mejora asintótica de la aptitud, plantea un compromiso (\textit{trade-off}).
Mientras que el costo temporal crece indefinidamente de forma lineal, la calidad de la solución tiende a estancarse. Por tanto,
una configuración intermedia (entre 100 y 500 reinicios) parece ofrecer el mejor balance, maximizando la calidad de la solución
sin incurrir en costos computacionales excesivos que aportan beneficios marginales mínimos.

\section{Conclusiones}
El presente estudio abordó el Enhanced Profitable Tour Problem (EPTP), un desafío de optimización combinatoria de alta complejidad
que modela situaciones críticas en la logística moderna y la planificación de rutas turísticas. La naturaleza NP-Hard del problema,
sumada a restricciones operativas estrictas como ventanas de tiempo y limitaciones de recursos, hace inviable el uso de métodos exactos
para instancias de tamaño realista, validando la necesidad de enfoques aproximados como el desarrollado en este informe.


La propuesta de solución se fundamentó en una metaheurística de búsqueda local tipo Hill-Climbing con estrategia de reinicios
múltiples (\textit{Restarts}). Esta elección demostró ser adecuada para el problema, logrando un equilibrio efectivo entre la
intensificación (explotación de vecindarios mediante operadores de \textit{Swap}, \textit{Addition} y \textit{2-opt}) y la
diversificación (exploración de nuevas áreas del espacio de búsqueda mediante reinicios aleatorios).

El análisis experimental permitió validar la robustez y escalabilidad del algoritmo. Respecto al **Experimento 1**, se concluye
que el método es altamente eficiente para instancias de hasta 140 nodos. Si bien el tiempo de ejecución exhibe un crecimiento
polinomial conforme aumenta el tamaño del problema, los valores absolutos se mantienen en el orden de fracciones de segundo,
lo cual confirma la viabilidad de la herramienta para aplicaciones en tiempo real. Asimismo, la alta tasa de factibilidad observada
sugiere que el mecanismo de penalización y los operadores de reparación implementados son efectivos para manejar las restricciones
de ventanas de tiempo.

En cuanto al **Experimento 2**, el estudio de los reinicios reveló un comportamiento de rendimientos decrecientes. Se demostró
que existe una relación lineal entre el número de reinicios y el tiempo de cómputo, mientras que la mejora en la calidad de la
solución (aptitud) se comporta de manera asintótica. Esto permite concluir que maximizar indiscriminadamente los reinicios no
es una estrategia eficiente; existe un punto de equilibrio (identificado en el rango de 100 a 500 reinicios para las instancias
probadas) donde se maximiza la relación costo-beneficio. Superar este umbral conlleva un costo computacional alto con ganancias
marginales en la función objetivo.

Entre las ventajas de la propuesta destacan su simplicidad de implementación, su bajo consumo de recursos computacionales y su
capacidad para generar soluciones factibles de manera consistente. Sin embargo, como desventaja inherente al método de búsqueda local,
existe el riesgo de estancamiento en óptimos locales, el cual, aunque mitigado por los reinicios, no se elimina por completo.

Como trabajo futuro, se sugiere la exploración de metaheurísticas poblacionales, como Algoritmos Genéticos o Colonias de Hormigas,
que podrían ofrecer mecanismos de diversificación más sofisticados que el reinicio aleatorio. Asimismo, sería pertinente extender el
modelo para abordar variantes estocásticas del problema, donde los tiempos de viaje o los beneficios sean variables aleatorias,
acercando aún más la solución a la incertidumbre de los entornos reales.

\bibliographystyle{plain}
\bibliography{Referencias}

\section{Anexo}
\begin{algorithm}
\caption{Creación de Solución Aleatoria}
\label{alg:crear_solucion_aleatoria}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Datos de nodos $N$, Datos de usuario $U$}
\Output{Solución inicial aleatoria $S$}

$tamano \gets (N.num\_nodos / 2) + 1$\;

\tcp{El tour siempre comienza en el nodo 0}
$S.tour[0] \gets 0$\;

\tcp{Creación del conjunto de candidatos}
$Set \gets \emptyset$\;
\For{$i \gets 1$ \KwTo $N.num\_nodos - 1$}{
    Agregar $i$ a $Set$\;
}

\For{$i \gets 1$ \KwTo $tamano - 1$}{
    $rand \gets$ entero aleatorio en $[0, |Set| - 1]$\;
    
    $S.tour[i] \gets Set[rand]$\;
    
    \tcp{Eliminación del candidato usado}
    $Set[rand] \gets Set.ultimo$\;
    Eliminar último elemento de $Set$\;
}

\ForEach{$nodo$ en $Set$}{
    Agregar $nodo$ a $S.no\_visitados$\;
}

\tcp{Cálculo de aptitud}
FuncionEvaluacion($S, N, U$)\;

\Return $S$\;
\end{algorithm}

\begin{algorithm}
\caption{Función de Evaluación de Solución}
\label{alg:funcion_evaluacion}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Solución $S$, Datos Nodos $N$, Datos Usuario $U$}
\Output{Aptitud y Factibilidad actualizadas en $S$}

$S.factibilidad \gets F$\;
$aptitud \gets 0, tiempo \gets 0, penalizacion \gets 0$\;
$M \gets |S.tour|$\;

\For{$i \gets 0$ \KwTo $M - 1$}{
    $u \gets S.tour[i]$\;
    
    \tcp{Sumar beneficios}
    $aptitud \gets aptitud + U.beneficio\_nodo[u]$\;
    \If{$i < M - 1$}{
        $v \gets S.tour[i+1]$\;
        $aptitud \gets aptitud + U.beneficio\_arco[u][v]$\;
    }
    
    \tcp{Acumular tiempos}
    $tiempo \gets tiempo + N.tiempo\_servicio[u]$\;
    \If{$i < M - 1$}{
        $tiempo \gets tiempo + N.tiempo\_viaje[u][v]$\;
    }
    
    \tcp{Verificar ventana de tiempo (inicio)}
    \If{$tiempo < N.ventana[u].inicio$}{
        $tiempo \gets tiempo + (N.ventana[u].inicio - tiempo)$\;
    }
    
    \tcp{Verificar ventana de tiempo (fin)}
    \If{$(tiempo + N.tiempo\_servicio[u]) > N.ventana[u].fin$}{
        $penalizacion \gets penalizacion + (tiempo + N.tiempo\_servicio[u]) - N.ventana[u].fin$\;
        $S.factibilidad \gets I$\;
    }
}

\tcp{Cierre del ciclo (retorno al inicio)}
$ultimo \gets S.tour[M-1]$\;
$primero \gets S.tour[0]$\;

$aptitud \gets aptitud + U.beneficio\_arco[ultimo][primero]$\;
$tiempo \gets tiempo + N.tiempo\_viaje[ultimo][primero]$\;

\tcp{Validación de tiempo máximo total}
\If{$tiempo > U.tiempo\_max$}{
    $penalizacion \gets penalizacion + (tiempo - U.tiempo\_max)$\;
    $S.factibilidad \gets I$\;
}

$aptitud \gets aptitud - (penalizacion \times 10)$\;
$S.aptitud \gets aptitud$\;
$S.tiempo \gets tiempo$\;

\end{algorithm}

\begin{algorithm}
\caption{Operador de Adición}
\label{alg:addition}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Solución actual $S$, índice $k$, Datos $N, U$}
\Output{Solución candidata $S_{cand}$}

$S_{best} \gets S$\;
$nodo \gets S.no\_visitados[k]$\;

\For{$i \gets 1$ \KwTo $|S.tour|$}{
    $S' \gets S$\;
    Insertar $nodo$ en $S'.tour$ en posición $i$\;
    FuncionEvaluacion($S', N, U$)\;
    
    \If{$S'.aptitud > S_{best}.aptitud$}{
        $S_{best} \gets S'$\;
    }
}

\eIf{$S_{best}.aptitud > S.aptitud$}{
    $S_{cand} \gets S_{best}$\;
    Eliminar $nodo$ de $S_{cand}.no\_visitados$\;
}{
    $S_{cand} \gets S$\;
}
\end{algorithm}

\begin{algorithm}
\caption{Operador de Eliminación}
\label{alg:eliminacion}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Solución actual $S$, índice $k$, Datos $N, U$}
\Output{Solución candidata $S_{cand}$}

$S_{cand} \gets S$\;

\tcp{El nodo inicial (depósito) es inmutable}
\If{$k \neq 0$}{
    $u \gets S_{cand}.tour[k]$\;
    Eliminar elemento en posición $k$ de $S_{cand}.tour$\;
    Agregar $u$ a $S_{cand}.no\_visitados$\;
}

FuncionEvaluacion($S_{cand}, N, U$)\;
\Return $S_{cand}$\;
\end{algorithm}

\begin{algorithm}
\caption{Operador Swap (Best Improvement)}
\label{alg:swap}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Solución actual $S$, índice $k$, Datos $N, U$}
\Output{Solución candidata $S_{cand}$}

$S_{best} \gets S$\;

\For{$i \gets 1$ \KwTo $|S.tour| - 1$}{
    \If{$i \neq k$}{
        $S' \gets S$\;
        Intercambiar $S'.tour[k]$ con $S'.tour[i]$\;
        FuncionEvaluacion($S', N, U$)\;
        
        \If{$S'.aptitud > S_{best}.aptitud$}{
            $S_{best} \gets S'$\;
        }
    }
}

$S_{cand} \gets S_{best}$\;
\end{algorithm}

\begin{algorithm}
\caption{Operador Exchange (Best Improvement)}
\label{alg:exchange}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Solución actual $S$, índice no visitado $k$, Datos $N, U$}
\Output{Solución candidata $S_{cand}$}

$S_{best} \gets S$\;

\For{$i \gets 1$ \KwTo $|S.tour| - 1$}{
    $S' \gets S$\;
    \tcp{Intercambio entre lista de no visitados y tour}
    Intercambiar $S'.no\_visitados[k]$ con $S'.tour[i]$\;
    FuncionEvaluacion($S', N, U$)\;
    
    \If{$S'.aptitud > S_{best}.aptitud$}{
        $S_{best} \gets S'$\;
    }
}

$S_{cand} \gets S_{best}$\;
\end{algorithm}

\begin{algorithm}
\caption{Movimiento 2-Opt (Intercambio Adyacente)}
\label{alg:opt_2}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Solución $S$, posiciones $p_1, p_2$, Datos $N, U$}
\Output{Solución candidata $S_{cand}$}

$S_{cand} \gets S$\;

\tcp{Proteger el depósito (0) y ajustar índice circular}
\If{$p_1 \neq 0 \land p_2 \neq 0$}{
    $p_2 \gets p_2 \pmod{|S.tour|}$\;
    Intercambiar $S_{cand}.tour[p_1]$ con $S_{cand}.tour[p_2]$\;
}

FuncionEvaluacion($S_{cand}, N, U$)\;
\Return $S_{cand}$\;
\end{algorithm}

\begin{algorithm}
\caption{Hill Climbing con Restart y Selección Aleatoria de movimientos}
\label{alg:hill_climbing_restarts}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Salida}

\Input{Usuarios $\mathcal{U}$, Nodos $N$, MaxReinicios $M_r$}
\Output{Mejores soluciones encontradas para cada usuario}

\For{cada usuario $u \in \mathcal{U}$}{
    $S_{best} \gets \emptyset$\;
    
    \For{$r \gets 1$ \KwTo $M_r$}{
        $S \gets$ CrearSolucionAleatoria($N, u$)\;
        $OptimoLocal \gets \text{Falso}$\;
        
        \While{No $OptimoLocal$}{
            $S_{cand} \gets S$\;
            
            \eIf{$S$ es infactible $\land$ $|S.tour| > 2$}{
                \tcp{Forzar reparación reduciendo tamaño}
                $S_{cand} \gets$ BuscarMejorVecino(Eliminación, $S$)\;
            }{
                \tcp{Selección estocástica del operador}
                $Op \gets$ Aleatorio(\{Opt-2, Addition, Swap, Exchange, Eliminación\})\;
                
                \tcp{Estrategia Best Improvement: Se explora todo el vecindario del tipo seleccionado}
                $S_{cand} \gets$ BuscarMejorVecino($Op, S$)\;
            }
            
            \eIf{$f(S_{cand}) > f(S)$}{
                $S \gets S_{cand}$ \tcp*{Aceptar mejora}
            }{
                $OptimoLocal \gets \text{Verdadero}$ \tcp*{Estancamiento}
            }
        }
        
        \If{$f(S) > f(S_{best})$}{
            $S_{best} \gets S$\;
        }
    }
    Guardar $S_{best}$\;
}
\end{algorithm}



\end{document} 
